
== Application

////
The Application Layer elements are typically used to model the Application Architecture that describes the structure, behavior, and interaction of the applications of the enterprise.

* *_What_* software and applications this is relevant to accomplish

Application workloads will consider the components, these will include, but not limited to SLES4SAP, SALT, TF, Repos, etc. Considerations for Availability, Performance, should be outlined here.

# Application (Workloads)
#ADOC_ATTRIBUTES+=" --attribute Terraform=1"
#ADOC_ATTRIBUTES+=" --attribute SUSE Linux=1"
#ADOC_ATTRIBUTES+=" --attribute SALT=1"
#ADOC_ATTRIBUTES+=" --attribute SAP=1"
#ADOC_ATTRIBUTES+=" --attribute Netweaver=1"
#ADOC_ATTRIBUTES+=" --attribute HA=1"
 
////
=== SUSE Linux Enterprise Server for SAP Applications

SUSE Linux Enterprise Server for SAP Applications is a product formed from a bundle of software and services.  It is targeted specifically at customers running SAP workloads. At it's foundation is SUSE Linux Enterprise Server and the High Availability Extension with many additional components and benefits for running SAP Applications.
// "At it's foundation" -> "The foundation is" ??

=== SAP Application

In order to use the automation project, there are preliminary steps which need to be taken. One of these is to prepare the SAP installation software. The SAP software can be downloaded from https://launchpad.support.sap.com/#/softwarecenter, this will need to be performed manually before you start the automated deployment.

=== Presenting the SAP Media

After downloading the required SAP software, the files must be presented via cloud storage so it is accessible from the new installed virtual machines / instances.

ifeval::[ "{cloud}" == "Azure" ]

Azure offers shared storage (Azure Files) for applications using the Server Message Block (SMB) protocol which is a simple way to upload the SAP Media to it an use it from the installed machines for the SAP installation.

To use Azure Storage, you need to create first a storage account.

https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction

endif::[]

ifeval::[ "{cloud}" == "AWS" ]

When deploying on AWS, an S3 Bucket is required to store the SAP Media. Using the AWS Console:

* Create an S3 bucket.  (The example shows a bucket called mysapmedia, but a unique name should be used.)
* Create a folder within the bucket.
* Upload the SAP media to the folder within the S3 bucket.

image::s3_bucket.png[scalewidth=80%] 


endif::[]

ifeval::[ "{cloud}" == "GCP" ]
When deploying on GCP, a Storage Bucket is required to store the SAP Media. Using the AWS Console:

* Create a storage bucket.
* Create two folders (for the SAP HANA and SAP NetWeaver media) within the bucket.
* Upload the SAP media to the folder within the S3 bucket.

image::gcp_storage_bucket.png[scalewidth=80%] 
TIP:: The example shows a bucket called _sap-automation-media_, but a unique name should be used.
endif::[]

ifeval::[ "{cloud}" == "Libvirt" ]
Libvirt - NFS share
endif::[]

=== Terraform

Terraform is an open source tool created by HashiCorp for building, changing and versioning infrastructure.

As a infrastructure provisioning tool, it is responsible for creating the servers, but also load balancers, queues, monitoring, subnet configurations, firewall settings, routing rules, SSL certificates, and many other infrastructure components.

Terraform is seen as cloud-agnostic and allows a single configuration to be used to manage multiple providers. This simplifies management and orchestration, helping operators build large-scale multi-cloud infrastructures.

It is imporant to note that Terraform can not simply create a landscape with a press of a button in another cloud. The cloud providers use different types of infrastructure. For example the VMs, load balancers and other services offered by AWS are very different to those in Azure and Google Cloud.

Terraform’s approach is that code is written specific to a (cloud)provider and will take advantage of the provider’s unique functionality, whilst the code will need to be modified when used on a different cloud provider, being able to use the same language and toolset for all providers makes this effortless.

The name Terraform uses for these cloud specific modules is "provider". So for example the _Azure Provider_ can be used to configure infrastructure in Microsoft Azure using the Azure Resource Manager API's.

Configuration files describe to Terraform which components need to deploy in order to support the application. One of the first steps is to run the terraform command, this will generate an execution plan which describes the actions Terraform will perform to get to the planned desired state.  The plan is in the form of a list of cloud infrastructure to create, delete and modify, if this looks correct, the final step is to execute the plan to create the described infrastructure.

SUSE provides Terraform configuration files for AWS, Azure, GCE and libvirt.

An open source version of Terraform is shipped within the Public Cloud Module of {sles4sap}

ifeval::[ "{cloud}" == "Azure" ]
In addition Azure provide an easy to access web based commandline (cloudshell) where Terraform is already pre-installed.

// FixMe provide link

endif::[]

ifeval::[ "{cloud}" == "AWS" ]

In addition, AWS provides an easy to access web based command line shell where Terraform can be downloaded and installed.

https://console.aws.amazon.com/cloudshell/

endif::[]

{cloud} provides different types of storage suitable for supporting SAP workloads, so it is important to fully understand the SAP requirements for {cloud}.

The storage configuration included in the Terraform files are provided as an initial suggestion, based on best practices. It is still important to continue analyzing the storage utilization patterns during runtime of the application, it may be that the SAP workload is not utilizing all the storage bandwidth or IOPS provided. Therefore, downsizing storage may be an option.

The suggestions from the Terraform files for the storage configurations are meant as good directions to start with. But you still should analyze the storage utilization patterns during runtime of the application. It could be the case that you realize that you are not utilizing all the storage bandwidth or IOPS provided. Therefore you might consider downsizing on storage or you will see the opposite way and your workload might need more storage throughput than suggested with these configurations. As a result, you might need to change the capacity, IOPS or throughput. Independent what you needs between storage capacity required, storage latency needed, storage throughput and IOPS required and least expensive configuration, {cloud} offers enough different storage types with different capabilities and different price points to find and adjust to the right compromise for you and your SAP workload.

=== SALT

SaltStack’s configuration management system lets you define the applications, files, and other settings required on a specific system. The running system is continuously evaluated against the defined configuration, and changes are made as necessary.

 * Salt works with "States" which express the required state a host should be in, using small, easy to read, easy to understand configuration files.
 * The automation is written as "formulas" which are a collection of pre-written Salt States and Salt Pillar files.
 * The Pillar files are the variables and data used to build the system.

SLES-for-SAP Applications ships with all the Salt tools as part of the distribution and are available to use as needed.

Salt formulas can be applied in two ways:

Salt Master with Salt Client. All steps are executed on the Salt Master machine which sends instructions to the client to perform the required configuration actions.

Salt Client (Minion) only. All steps in must be executed on each individual Salt client where the formulas need to be executed.  This is the approach used by the SUSE Automation framework as it removes the need for a central master system.

==== Netweaver

The Netweaver formula for bootstrapping and managing the SAP Netweaver platform takes care of:

 * Extracting the required SAP files for SAP Media (.tar,.sar,.exe)
 * and setting up
 ** ASCS instance
 ** ERS instance
 ** PAS instance
 ** AAS instance
 ** Database instance (currently only HANA)

Besides that, the formula sets up all of the prerequisites as:

 * Hostnames
 * Virtual addresses
 * NFS mounts
 * Shared disks
 * SWAP partition space

The Salt formula follows the best practices defined in the official SUSE documentation http://documentation.suse.com/sbp

==== HANA

The HANA formula takes care of the following:

* Extract the required SAP files for SAP Media (.tar,.sar,.exe)
* Install SAP HANA.
* Apply "saptune" for HANA to configure and tune the OS for HANA usage
* Configure SAP System Replication.
* Preconfigure the High Availability cluster requirements.
* Configure the SAP HANA Prometheus exporter


==== HA

The HA bootstrap formula takes care of creating and managing a high availability cluster:

ifeval::[ "{cloud}" == "Azure" ]
 * Create and configure the High Availability cluster, pacemaker, corosync, SBD and SAP resource agents.
 * Adjustments for the Azure Infrastructure
 * Handle Netweaver, HANA and DRBD
endif::[]

ifeval::[ "{cloud}" == "AWS" ]
 * Create and configure the High Availability cluster, pacemaker, corosync, EC2 fencing and SAP resource agents.
 * Adjustments for the AWS Infrastructure
 * Handle Netweaver, HANA
endif::[]

ifeval::[ "{cloud}" == "GCP" ]
 * GCP Stuff
 * GCP Stuff
 * GCP Stuff
endif::[]

The formula provides the capability to create and configure a multi node HA cluster. Here are some of the features:

* Initialize a cluster
* Join a node to an existing cluster
* Remove a node from an existing cluster
* Configure the pre-requirements (install required packages, configure ntp/chrony, create ssh-keys, etc)
* Auto detect if the cluster is running in a cloud provider (Azure, AWS, or GCP)
* Configure SBD (if needed)
* Configure Corosync
* Configure the resource agents
* Install and configure the monitoring ha_cluster_exporter

// SM: Q: this should be cloud specific; 
// PS: A: we are here describe the formulas
//        and no as this concept can be used at any cloud for sbd fencing. e.g. in azure we have more than one option
// FIXME - provide more information on the case and better explanation
Depending on the cloud requirements it may need an iSCSI server to be able to provide a shared disk for fencing where we use the iscsi-formula from SaltStack

===== Other dependent services 

// SM: Azure specific?
// PS: No, as this could be used on any cloud. Azure provides 2 additional ways
//     and we describe the formulas here
// FIXME - provide more information on the case
====== HA NFS Service 

To build a HA NFS Service if there is none available, we can create one with help of 3 Linux services and the following

 * DRBD formula
 * HA formula
 * NFS formula from SaltStack

====== iSCSI Service

The iSCSI-formula from SaltStack is able to deploy iSNS, iSCSI initiator, and iSCSI target packages, manage configuration files and then starts the associated iSCSI services.

====== NFS formula
A SaltStack formula to install and configure nfs server and client.

=== Monitoring
SUSE continually try to improve user experience,  one of the developments is how to provide a modern solution to monitor the several High Availability clusters that manage SAP HANA and SAP Netweaver. The Monitoring components use the Prometheus toolkit and the Grafana project to visualize the data.  In order to be able to monitor the clusters on either HANA or Netweaver SUSE have written Prometheus exporters whicah ship as part of SLES for SAP.

==== SAP HANA Database Exporter
The exporter provide metrics from more than one database or tenant. It provides

 * Memory metrics
 * CPU metrics
 * Disk usage metrics
 * I/O metrics
 * Network metrics
 * Top queries consuming time and memory

==== High Availability Cluster Exporter
Enables monitoring of Pacemaker, Corosync, SBD, DRBD and other components of High Availability clusters. This provides the ability to easily monitor cluster status and health.

 * Pacemaker cluster summary, nodes, and resource status
 * Corosync ring errors and quorum votes. Currently, only Corosync version 2 is supported.
 * Health status of SBD devices.
 * DRBD resources and connections status. Currently, only DRBD version 9 is supported.

==== SAP Host Exporter
Enables the monitoring of SAP Netweaver, SAP HANA, and other applications. Gathered metrics are the data that can be obtained by running the sapcontrol command.

 * SAP start service process list
 * SAP enqueue server metrics
 * SAP application server dispatcher metrics
 * SAP internal alerts


ifdef::Availability[]
include::./Availability/SA.adoc[]
endif::Availability[]

ifdef::Performance[]
include::./Performance/SA.adoc[]
endif::Performance[]

ifdef::Security[]
include::./Security/SA.adoc[]
endif::Security[]

ifdef::Integrity[]
include::./Integrity/SA.adoc[]
endif::Integrity[]

